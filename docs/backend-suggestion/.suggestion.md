# Backend SaaS Architecture Suggestions

## Problem Analysis

**Core Issue**: GA engine (DEAP) + computational intensity + Django dependency conflicts
- DEAP runs on Python 3.8+, matplotlib/numpy specific versions
- Django/DRF may require different Python versions or conflicting dependencies
- GA scheduling is CPU-intensive (seconds to minutes), blocking request-response cycle
- Not suitable for traditional web framework synchronous execution

---

## Architecture: **Microservices with Task Queue**

### Recommended Stack

```
┌─────────────────┐      ┌──────────────────┐      ┌─────────────────────┐
│  Web API        │─────▶│  Message Queue   │─────▶│  GA Worker Service  │
│  (FastAPI/Flask)│      │  (Redis/RabbitMQ)│      │  (Pure Python+DEAP) │
└─────────────────┘      └──────────────────┘      └─────────────────────┘
        │                                                      │
        ▼                                                      ▼
   PostgreSQL                                          Output Storage
   (metadata, users)                                   (S3/MinIO/FileSystem)
```

**Why This Works**:
- **Isolation**: GA engine runs in separate worker process with own Python env
- **Async**: Long-running GA jobs don't block API responses
- **Scalability**: Spin up multiple workers for parallel job processing
- **Flexibility**: API and workers use different Python versions if needed

---

## Option 1: **FastAPI + Celery + Redis** (Recommended)

**Components**:
1. **FastAPI** (API layer) – Modern, async, auto-docs, fast
2. **Celery** (task queue) – Battle-tested async job processing
3. **Redis** (broker + cache) – Message queue + result backend
4. **PostgreSQL** (persistence) – User data, job metadata, schedules
5. **Docker** (deployment) – Isolate GA worker environment

**Flow**:
```
Client → POST /schedule/create
       → API validates input, stores in DB, enqueues Celery task
       → Returns task_id immediately (202 Accepted)
       
Client → GET /schedule/status/{task_id}
       → Returns: PENDING | RUNNING | SUCCESS | FAILED
       
Client → GET /schedule/result/{task_id}
       → Returns final schedule JSON + download links

Worker → Picks task from Redis
       → Runs `run_standard_workflow()` in isolated env
       → Stores output in S3/MinIO
       → Updates DB with result location
```

**Pros**:
- No dependency conflicts (FastAPI ≠ GA worker environment)
- FastAPI uses latest Python; GA worker uses Python 3.9/3.10 as needed
- Celery handles retries, progress tracking, distributed workers
- Can use Docker Compose for local dev, Kubernetes for production

**Cons**:
- Slightly more complex setup (3+ services)
- Need to manage Celery worker lifecycle

---

## Option 2: **Flask + RQ + Redis** (Simpler Alternative)

**Components**:
1. **Flask** (API layer) – Lightweight, mature ecosystem
2. **RQ (Redis Queue)** (task queue) – Simpler than Celery, Redis-only
3. **Redis** (broker + storage)
4. **PostgreSQL** (persistence)

**Why RQ > Celery**:
- Pure Python, easier to debug
- No complex configuration (vs Celery's brokers/backends)
- Built-in dashboard for monitoring

**Trade-offs**:
- RQ tied to Redis (Celery supports RabbitMQ, SQS, etc.)
- Less feature-rich than Celery (no chord/chain patterns)
- Still production-ready (used by GitLab, Sentry)

---

## Option 3: **Pure FastAPI + Background Tasks** (Quick Prototype)

For MVP/small scale:

**Components**:
- FastAPI with `BackgroundTasks`
- SQLite/PostgreSQL
- No separate queue infrastructure

**Flow**:
```python
@app.post("/schedule/create")
async def create_schedule(data: ScheduleInput, background_tasks: BackgroundTasks):
    job_id = create_job_record(data)
    background_tasks.add_task(run_ga_workflow, job_id, data)
    return {"job_id": job_id, "status": "queued"}
```

**Pros**:
- Minimal infrastructure
- Fast prototyping
- Single Python environment

**Cons**:
- **Not production-ready**: Tasks die if API restarts
- No task persistence, retries, or distribution
- Single-threaded processing
- Use only for demos or <100 users

---

## Dependency Isolation Strategies

### A. **Docker Multi-Stage Build**
```dockerfile
# Worker Dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements-worker.txt .
RUN pip install -r requirements-worker.txt
COPY src/ ./src/
COPY config/ ./config/
CMD ["celery", "-A", "worker", "worker"]
```

```dockerfile
# API Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements-api.txt .
RUN pip install -r requirements-api.txt
COPY api/ ./api/
CMD ["uvicorn", "api.main:app"]
```

**Separate Requirements**:
- `requirements-api.txt`: FastAPI, SQLAlchemy, Pydantic
- `requirements-worker.txt`: DEAP, numpy, matplotlib, your GA code

### B. **Virtual Environments** (Local Dev)
```
/schedule-engine
  /api-env          ← Python 3.11, FastAPI
  /worker-env       ← Python 3.9, DEAP
  /src              ← Shared GA code
```

Run API: `api-env/bin/uvicorn api.main:app`
Run worker: `worker-env/bin/celery -A worker worker`

### C. **Git Submodules** (Extreme Isolation)
```
/schedule-saas
  /api              ← FastAPI project (Python 3.11)
  /ga-engine        ← Git submodule pointing to schedule-engine
```

Worker imports GA engine as module, runs in own container.

---

## Recommended Implementation Phases

### Phase 1: Proof of Concept (Week 1-2)
- **Tech**: FastAPI + RQ + Redis + SQLite
- **Features**: 
  - POST endpoint to submit schedule request
  - RQ worker calls `run_standard_workflow()`
  - GET endpoint to check status
  - Store results in filesystem
- **Goal**: Validate architecture, no auth/UI

### Phase 2: MVP (Week 3-6)
- **Add**: PostgreSQL, JWT auth, user management
- **Features**:
  - Multi-tenancy (users own their schedules)
  - Input validation with Pydantic models
  - WebSocket for real-time progress updates
  - Download schedules as JSON/Excel
- **Deployment**: Docker Compose on single VPS

### Phase 3: Production (Month 2-3)
- **Switch**: RQ → Celery (if scaling needed)
- **Add**: 
  - S3/MinIO for output storage
  - Rate limiting (per user/tier)
  - Monitoring (Prometheus, Grafana)
  - Horizontal scaling (multiple workers)
- **Deployment**: Kubernetes or AWS ECS

---

## Data Flow Example

### 1. Client Submits Schedule Request
```json
POST /api/v1/schedules
{
  "courses": [...],
  "groups": [...],
  "instructors": [...],
  "rooms": [...],
  "config": {
    "pop_size": 100,
    "generations": 500
  }
}
```

**API Response** (immediate):
```json
{
  "job_id": "uuid-1234",
  "status": "queued",
  "estimated_time": "2-5 minutes"
}
```

### 2. Worker Processes Job
```python
@celery_app.task
def run_schedule_job(job_id: str, input_data: dict):
    update_job_status(job_id, "running")
    
    try:
        # Save input JSON to temp files (GA engine expects file paths)
        data_dir = prepare_input_files(input_data)
        
        # Call existing GA engine
        result = run_standard_workflow(
            pop_size=input_data["config"]["pop_size"],
            generations=input_data["config"]["generations"],
            data_dir=data_dir,
            output_dir=f"temp/{job_id}"
        )
        
        # Upload outputs to S3
        output_urls = upload_to_storage(job_id, result)
        
        # Update DB
        update_job_status(job_id, "completed", result=output_urls)
        
    except Exception as e:
        update_job_status(job_id, "failed", error=str(e))
```

### 3. Client Polls Status
```
GET /api/v1/schedules/uuid-1234/status
→ {"status": "running", "progress": 60}

GET /api/v1/schedules/uuid-1234/status
→ {"status": "completed", "result_url": "https://..."}
```

### 4. Client Downloads Results
```
GET /api/v1/schedules/uuid-1234/download
→ Returns schedule.json, calendar.png, plots.zip
```

---

## Avoiding Django Issues

**Why NOT Django**:
1. Heavy ORM for simple CRUD
2. Monolithic structure (admin, templates, middleware you won't use)
3. Sync-first design (async support added later)
4. Potential dependency conflicts with scientific stack

**FastAPI Advantages**:
- Built on Starlette (pure async)
- Pydantic validation (matches your JSON schemas)
- Automatic OpenAPI docs (instant API testing UI)
- Minimal footprint (just routing + validation)
- Native async/await for database calls

**If Must Use Django**:
- Use **Django Ninja** (FastAPI-like layer on Django)
- Run GA in separate Python process via `subprocess` or Celery
- Keep Django on Python 3.11, GA worker on Python 3.9

---

## Code Organization

```
schedule-saas/
├── api/                        # FastAPI application
│   ├── main.py                # App entry point
│   ├── routers/
│   │   ├── auth.py            # JWT, user management
│   │   ├── schedules.py       # POST /schedules, GET /schedules/{id}
│   │   └── webhooks.py        # External integrations
│   ├── models/                # SQLAlchemy models
│   │   ├── user.py
│   │   └── schedule_job.py
│   ├── schemas/               # Pydantic request/response models
│   │   └── schedule.py
│   └── dependencies.py        # Auth, DB session injection
│
├── worker/                     # Celery/RQ worker
│   ├── tasks.py               # Job definitions
│   ├── runner.py              # Wrapper around GA engine
│   └── storage.py             # S3/MinIO upload logic
│
├── schedule-engine/           # Your existing GA code (Git submodule or symlink)
│   ├── src/
│   ├── config/
│   └── main.py
│
├── tests/
│   ├── test_api.py
│   └── test_worker.py
│
├── docker/
│   ├── api.Dockerfile
│   └── worker.Dockerfile
│
├── docker-compose.yml         # Local dev stack
├── requirements-api.txt       # FastAPI, SQLAlchemy, JWT
└── requirements-worker.txt    # DEAP, numpy, matplotlib
```

---

## Security Considerations

1. **Input Validation**: Use Pydantic to validate course/room data prevents injection
2. **Resource Limits**: Cap `pop_size`, `generations` per user tier (prevent DoS)
3. **Timeouts**: Kill GA jobs exceeding time limit (use Celery `time_limit`)
4. **File Isolation**: Store user outputs in isolated buckets/folders
5. **Rate Limiting**: Use `slowapi` or Redis-based limiters
6. **Auth**: JWT with refresh tokens, hash passwords with bcrypt

---

## Cost Optimization

- **Compute**: Workers on spot instances (GA jobs are resumable)
- **Storage**: Delete old outputs after 30 days, compress JSONs
- **Cache**: Redis cache for repeated input patterns (same courses/rooms)
- **Tiers**: 
  - Free: 5 jobs/day, max 100 generations
  - Pro: Unlimited jobs, max 1000 generations, priority queue
  - Enterprise: Dedicated workers, custom constraints

---

## Monitoring & Observability

- **Metrics**: Prometheus → track job duration, failure rate, queue length
- **Logging**: Structured JSON logs → ELK stack or CloudWatch
- **Alerts**: Slack/email when worker crashes, queue backs up >50 jobs
- **Tracing**: OpenTelemetry to track request → queue → worker → result

---

## Migration Path from Current Code

### Minimal Changes Needed
1. **Wrap `run_standard_workflow()`** in task function
2. **Add progress callbacks**: Modify DEAP loop to emit progress events
3. **Handle file I/O**: Convert JSON strings ↔ temp files for GA engine
4. **Error handling**: Catch exceptions, store in DB for user feedback

### Example Worker Wrapper
```python
# worker/runner.py
import json
import tempfile
from pathlib import Path
from src.workflows import run_standard_workflow

def execute_ga_job(job_id: str, input_data: dict) -> dict:
    """
    Bridge between API (JSON) and GA engine (file-based).
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        # Write JSON inputs to files
        data_dir = Path(tmpdir) / "data"
        data_dir.mkdir()
        
        (data_dir / "Course.json").write_text(json.dumps(input_data["courses"]))
        (data_dir / "Groups.json").write_text(json.dumps(input_data["groups"]))
        (data_dir / "Instructors.json").write_text(json.dumps(input_data["instructors"]))
        (data_dir / "Rooms.json").write_text(json.dumps(input_data["rooms"]))
        
        # Run GA (your existing code)
        result = run_standard_workflow(
            pop_size=input_data["config"]["pop_size"],
            generations=input_data["config"]["generations"],
            data_dir=str(data_dir),
            output_dir=str(Path(tmpdir) / "output"),
        )
        
        # Read outputs
        output_path = Path(result["output_path"])
        schedule_json = (output_path / "schedule.json").read_text()
        
        return {
            "schedule": json.loads(schedule_json),
            "metrics": {
                "hard_violations": result["best_individual"].fitness.values[0],
                "soft_penalty": result["best_individual"].fitness.values[1],
            },
            "output_files": list(output_path.glob("*.png"))  # Plots for upload
        }
```

**No core GA changes needed** – just I/O adapters.

---

## Alternatives to Python Backend

### If Dependency Hell Persists

**Option A: Serverless Functions**
- Deploy GA engine as AWS Lambda / Google Cloud Run
- API (any language) triggers function via HTTP
- Pros: Zero infrastructure management, auto-scaling
- Cons: 15min timeout (Lambda), cold starts, expensive for long jobs

**Option B: Separate Services**
- API in Node.js/Go (no Python conflicts)
- GA engine as standalone Python service
- Communicate via REST or gRPC
- Pros: Complete isolation, use best tool per layer
- Cons: More complex deployment

**Option C: WebAssembly (Experimental)**
- Compile Python to WASM via Pyodide
- Run GA in browser or edge workers
- Pros: No backend needed for small schedules
- Cons: Limited libraries, performance hit, experimental

---

## Recommended Choice: FastAPI + Celery

**Justification**:
- **Proven**: Used by Uber, Robinhood, Netflix for async processing
- **Python-native**: Leverage existing GA code with minimal changes
- **Scalable**: Start with 1 worker, scale to 100s
- **Flexible**: Easy to add features (webhooks, real-time updates)
- **Maintainable**: Clear separation (API ≠ worker), testable components

**Next Steps**:
1. Create `api/` folder with FastAPI skeleton
2. Set up Celery worker calling `run_standard_workflow()`
3. Docker Compose with Redis + PostgreSQL
4. Test end-to-end flow with sample data
5. Add auth, monitoring, deployment

---

## Resources

- **FastAPI**: https://fastapi.tiangolo.com
- **Celery**: https://docs.celeryq.dev
- **RQ**: https://python-rq.org
- **Docker Compose**: https://docs.docker.com/compose
- **Task Queue Comparison**: https://testdriven.io/blog/python-task-queues/

---

**Summary**: Decouple API (FastAPI) from GA worker (Celery), use task queue (Redis) for async job handling, isolate Python environments via Docker. Avoid Django to prevent dependency conflicts. Start with RQ for simplicity, migrate to Celery when scaling.
